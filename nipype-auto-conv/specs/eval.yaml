# This file is used to manually specify the semi-automatic conversion of
# 'nipype.interfaces.afni.utils.Eval' from Nipype to Pydra.
#
# Please fill-in/edit the fields below where appropriate
#
# Inputs
# ------
# in_file_a : file
#    input file to 1deval
# in_file_b : file
#    operand file to 1deval
# in_file_c : file
#    operand file to 1deval
# out_file : file
#    output image file name
# out1D : bool
#    output in 1D
# expr : str
#    expr
# start_idx : int
#    start index for in_file_a
# stop_idx : int
#    stop index for in_file_a
# single_idx : int
#    volume index for in_file_a
# other : file
#    other options
# num_threads : int
#    set number of threads
# outputtype : enum
#    AFNI output filetype
# args : str
#    Additional parameters to the command
# environ : dict
#    Environment variables
#
# Outputs
# -------
# out_file : file
#    output file
#
# Docs
# ----
# Evaluates an expression that may include columns of data from one or
#     more text files.
# 
#     For complete details, see the `1deval Documentation.
#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/1deval.html>`_
# 
#     Examples
#     --------
#     >>> from nipype.interfaces import afni
#     >>> eval = afni.Eval()
#     >>> eval.inputs.in_file_a = 'seed.1D'
#     >>> eval.inputs.in_file_b = 'resp.1D'
#     >>> eval.inputs.expr = 'a*b'
#     >>> eval.inputs.out1D = True
#     >>> eval.inputs.out_file =  'data_calc.1D'
#     >>> eval.cmdline
#     '1deval -a seed.1D -b resp.1D -expr "a*b" -1D -prefix data_calc.1D'
#     >>> res = eval.run()  # doctest: +SKIP
# 
#     
task_name: eval
nipype_name: Eval
nipype_module: nipype.interfaces.afni.utils
inputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    in_file_a: generic/file
    in_file_b: generic/file
    in_file_c: generic/file
    out_file: generic/file
    other: generic/file
  metadata:
  # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
outputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    out_file: generic/file
  callables:
  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
  # to set to the `callable` attribute of output fields
  templates:
  # dict[str, str] - `output_file_template` values to be provided to output fields
  requirements:
  # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
tests:
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    in_file_a:
    in_file_b:
    expr: '"a*b"'
    out1D: 'True'
    out_file:
  imports:
  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
doctests:
- cmdline: 1deval -a seed.1D -b resp.1D -expr "a*b" -1D -prefix data_calc.1D
  # str - the expected cmdline output
  inputs:
  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
  # If the field is of file-format type and the value is None, then the
  # '.mock()' method of the corresponding class is used instead.
    in_file_a:
    in_file_b:
    expr: '"a*b"'
    out1D: 'True'
    out_file:
  imports:
  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  directive: ''''
  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
