# This file is used to manually specify the semi-automatic conversion of
# 'nipype.interfaces.afni.model.Remlfit' from Nipype to Pydra.
#
# Please fill-in/edit the fields below where appropriate
#
# Inputs
# ------
# in_files : inputmultiobject
#    Read time series dataset
# matrix : file
#    the design matrix file, which should have been output from Deconvolve via the 'x1D' option
# polort : int
#    if no 'matrix' option is given, AND no 'matim' option, create a matrix with Legendre polynomial regressorsup to the specified order. The default value is 0, whichproduces a matrix with a single column of all ones
# matim : file
#    read a standard file as the matrix. You can use only Col as a name in GLTs with these nonstandard matrix input methods, since the other names come from the 'matrix' file. These mutually exclusive options are ignored if 'matrix' is used.
# mask : file
#    filename of 3D mask dataset; only data time series from within the mask will be analyzed; results for voxels outside the mask will be set to zero.
# automask : bool
#    build a mask automatically from input data (will be slow for long time series datasets)
# STATmask : file
#    filename of 3D mask dataset to be used for the purpose of reporting truncation-to float issues AND for computing the FDR curves. The actual results ARE not masked with this option (only with 'mask' or 'automask' options).
# addbase : inputmultiobject
#    file(s) to add baseline model columns to the matrix with this option. Each column in the specified file(s) will be appended to the matrix. File(s) must have at least as many rows as the matrix does.
# slibase : inputmultiobject
#    similar to 'addbase' in concept, BUT each specified file must have an integer multiple of the number of slices in the input dataset(s); then, separate regression matrices are generated for each slice, with the first column of the file appended to the matrix for the first slice of the dataset, the second column of the file appended to the matrix for the first slice of the dataset, and so on. Intended to help model physiological noise in FMRI, or other effects you want to regress out that might change significantly in the inter-slice time intervals. This will slow the program down, and make it use a lot more memory (to hold all the matrix stuff).
# slibase_sm : inputmultiobject
#    similar to 'slibase', BUT each file much be in slice major order (i.e. all slice0 columns come first, then all slice1 columns, etc).
# usetemp : bool
#    write intermediate stuff to disk, to economize on RAM. Using this option might be necessary to run with 'slibase' and with 'Grid' values above the default, since the program has to store a large number of matrices for such a problem: two for every slice and for every (a,b) pair in the ARMA parameter grid. Temporary files are written to the directory given in environment variable TMPDIR, or in /tmp, or in ./ (preference is in that order)
# nodmbase : bool
#    by default, baseline columns added to the matrix via 'addbase' or 'slibase' or 'dsort' will each have their mean removed (as is done in Deconvolve); this option turns this centering off
# dsort : file
#    4D dataset to be used as voxelwise baseline regressor
# dsort_nods : bool
#    if 'dsort' option is used, this command will output additional results files excluding the 'dsort' file
# fout : bool
#    output F-statistic for each stimulus
# rout : bool
#    output the R^2 statistic for each stimulus
# tout : bool
#    output the T-statistic for each stimulus; if you use 'out_file' and do not give any of 'fout', 'tout',or 'rout', then the program assumes 'fout' is activated.
# nofdr : bool
#    do NOT add FDR curve data to bucket datasets; FDR curves can take a long time if 'tout' is used
# nobout : bool
#    do NOT add baseline (null hypothesis) regressor betas to the 'rbeta_file' and/or 'obeta_file' output datasets.
# gltsym : list
#    read a symbolic GLT from input file and associate it with a label. As in Deconvolve, you can also use the 'SYM:' method to provide the definition of the GLT directly as a string (e.g., with 'SYM: +Label1 -Label2'). Unlike Deconvolve, you MUST specify 'SYM: ' if providing the GLT directly as a string instead of from a file
# out_file : file
#    output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
# var_file : file
#    output dataset for REML variance parameters
# rbeta_file : file
#    output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.
# glt_file : file
#    output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym'; GLTs from Deconvolve's command line will NOT be included.
# fitts_file : file
#    output dataset for REML fitted model
# errts_file : file
#    output dataset for REML residuals = data - fitted model
# wherr_file : file
#    dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise
# quiet : bool
#    turn off most progress messages
# verb : bool
#    turns on more progress messages, including memory usage progress reports at various stages
# goforit : bool
#    With potential issues flagged in the design matrix, an attempt will nevertheless be made to fit the model
# ovar : file
#    dataset for OLSQ st.dev. parameter (kind of boring)
# obeta : file
#    dataset for beta weights from the OLSQ estimation
# obuck : file
#    dataset for beta + statistics from the OLSQ estimation
# oglt : file
#    dataset for beta + statistics from 'gltsym' options
# ofitts : file
#    dataset for OLSQ fitted model
# oerrts : file
#    dataset for OLSQ residuals (data - fitted model)
# num_threads : int
#    set number of threads
# outputtype : enum
#    AFNI output filetype
# args : str
#    Additional parameters to the command
# environ : dict
#    Environment variables
#
# Outputs
# -------
# out_file : file
#    dataset for beta + statistics from the REML estimation (if generated)
# var_file : file
#    dataset for REML variance parameters (if generated)
# rbeta_file : file
#    output dataset for beta weights from the REML estimation (if generated)
# glt_file : file
#    output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym' (if generated)
# fitts_file : file
#    output dataset for REML fitted model (if generated)
# errts_file : file
#    output dataset for REML residuals = data - fitted model (if generated)
# wherr_file : file
#    dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise (if generated)
# ovar : file
#    dataset for OLSQ st.dev. parameter (if generated)
# obeta : file
#    dataset for beta weights from the OLSQ estimation (if generated)
# obuck : file
#    dataset for beta + statistics from the OLSQ estimation (if generated)
# oglt : file
#    dataset for beta + statistics from 'gltsym' options (if generated)
# ofitts : file
#    dataset for OLSQ fitted model (if generated)
# oerrts : file
#    dataset for OLSQ residuals = data - fitted model (if generated)
#
# Docs
# ----
# Performs Generalized least squares time series fit with Restricted
#     Maximum Likelihood (REML) estimation of the temporal auto-correlation
#     structure.
# 
#     For complete details, see the `3dREMLfit Documentation.
#     <https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dREMLfit.html>`_
# 
#     Examples
#     ========
# 
#     >>> from nipype.interfaces import afni
#     >>> remlfit = afni.Remlfit()
#     >>> remlfit.inputs.in_files = ['functional.nii', 'functional2.nii']
#     >>> remlfit.inputs.out_file = 'output.nii'
#     >>> remlfit.inputs.matrix = 'output.1D'
#     >>> remlfit.inputs.gltsym = [('SYM: +Lab1 -Lab2', 'TestSYM'), ('timeseries.txt', 'TestFile')]
#     >>> remlfit.cmdline
#     '3dREMLfit -gltsym "SYM: +Lab1 -Lab2" TestSYM -gltsym "timeseries.txt" TestFile -input "functional.nii functional2.nii" -matrix output.1D -Rbuck output.nii'
#     >>> res = remlfit.run()  # doctest: +SKIP
#     
task_name: remlfit
nipype_name: Remlfit
nipype_module: nipype.interfaces.afni.model
inputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    in_files: medimage/nifti1+list-of
    matrix: generic/file
    matim: generic/file
    mask: generic/file
    STATmask: generic/file
    addbase: generic/file+list-of
    slibase: generic/file+list-of
    slibase_sm: generic/file+list-of
    dsort: generic/file
    out_file: medimage/nifti1
    var_file: generic/file
    rbeta_file: generic/file
    glt_file: generic/file
    fitts_file: generic/file
    errts_file: generic/file
    wherr_file: generic/file
    ovar: generic/file
    obeta: generic/file
    obuck: generic/file
    oglt: generic/file
    ofitts: generic/file
    oerrts: generic/file
  metadata:
  # dict[str, dict[str, any]] - additional metadata to set on any of the input fields (e.g. out_file: position: 1)
outputs:
  omit:
  # list[str] - fields to omit from the Pydra interface
  rename:
  # dict[str, str] - fields to rename in the Pydra interface
  types:
  # dict[str, type] - override inferred types (use "mime-like" string for file-format types,
  # e.g. 'medimage/nifti-gz'). For most fields the type will be correctly inferred
  # from the nipype interface, but you may want to be more specific, particularly
  # for file types, where specifying the format also specifies the file that will be
  # passed to the field in the automatically generated unittests.
    out_file: medimage/nifti1
    var_file: generic/file
    rbeta_file: generic/file
    glt_file: generic/file
    fitts_file: generic/file
    errts_file: generic/file
    wherr_file: generic/file
    ovar: generic/file
    obeta: generic/file
    obuck: generic/file
    oglt: generic/file
    ofitts: generic/file
    oerrts: generic/file
  callables:
  # dict[str, str] - names of methods/callable classes defined in the adjacent `*_callables.py`
  # to set to the `callable` attribute of output fields
  templates:
  # dict[str, str] - `output_file_template` values to be provided to output fields
  requirements:
  # dict[str, list[str]] - input fields that are required to be provided for the output field to be present
tests:
- inputs:
  # dict[str, str] - values to provide to inputs fields in the task initialisation
  # (if not specified, will try to choose a sensible value)
    in_files:
    out_file:
    matrix:
    gltsym: '[("SYM: +Lab1 -Lab2", "TestSYM"), ("timeseries.txt", "TestFile")]'
  imports:
  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  expected_outputs:
  # dict[str, str] - expected values for selected outputs, noting that tests will typically
  # be terminated before they complete for time-saving reasons, and therefore
  # these values will be ignored, when running in CI
  timeout: 10
  # int - the value to set for the timeout in the generated test, 
  # after which the test will be considered to have been initialised 
  # successfully. Set to 0 to disable the timeout (warning, this could
  # lead to the unittests taking a very long time to complete)
  xfail: true
  # bool - whether the unittest is expected to fail or not. Set to false
  # when you are satisfied with the edits you have made to this file
doctests:
- cmdline: '3dREMLfit -gltsym "SYM: +Lab1 -Lab2" TestSYM -gltsym "timeseries.txt" TestFile -input "functional.nii functional2.nii" -matrix output.1D -Rbuck output.nii'
  # str - the expected cmdline output
  inputs:
  # dict[str, str] - name-value pairs for inputs to be provided to the doctest.
  # If the field is of file-format type and the value is None, then the
  # '.mock()' method of the corresponding class is used instead.
    in_files:
    out_file:
    matrix:
    gltsym: '[("SYM: +Lab1 -Lab2", "TestSYM"), ("timeseries.txt", "TestFile")]'
  imports:
  # list[nipype2pydra.task.importstatement] - list import statements required by the test, with each list item
  # consisting of 'module', 'name', and optionally 'alias' keys
  directive: ''''
  # str - any doctest directive to place on the cmdline call, e.g. # doctest: +ELLIPSIS
